
import os
from glob import glob

import minerl
from typing import List, Sequence

from vpt.agent import MineRLAgent
from dyna.data.data_loader import DataLoader


class ContiguousTrajectory:
    def __init__(self, video_path: str, json_path: str, uid: str):
        self.video_path = video_path
        self.json_path = json_path
        self.uid = uid

    def __str__(self) -> str:
        return f"T({self.uid})"

    def __repr__(self) -> str:
        return self.__str__()


class ContiguousTrajectoryDataLoader:
    def __init__(self, dataset_path: str):
        self.dataset_path = dataset_path

        # gather all unique IDs for every video/json file pair.
        unique_ids = glob(os.path.join(self.dataset_path, "*.mp4"))
        unique_ids = list(set([os.path.basename(x).split(".")[0] for x in unique_ids]))
        self.unique_ids = unique_ids

        # create ContiguousTrajectory objects for every mp4/json file pair.
        self.trajectories = []
        for unique_id in unique_ids:
            video_path = os.path.abspath(os.path.join(self.dataset_path, unique_id + ".mp4"))
            json_path = os.path.abspath(os.path.join(self.dataset_path, unique_id + ".jsonl"))
            t = ContiguousTrajectory(video_path, json_path, unique_id)
            self.trajectories.append(t)

    def __str__(self):
        return f"ContiguousTrajectoryDataLoader(n={len(self.trajectories)}, {self.dataset_path})"

class DataHandler:
    def __init__(self, dataset_paths: List[str]):
        self.dataset_paths = dataset_paths
        self.loaders = [ContiguousTrajectoryDataLoader(path) for path in self.dataset_paths]

    def get_batch(self, task_index: int):
        # a batch is a contiguous set of observation, action pairs where 
        pass


class ExpertDatasetUnroller:
    """Generates a window of state embeddings generated by a MineRLAgent. The agent
    assumes that the trajectories are fed in contiguously. This class is meant to be iterated over!
    """

    def __init__(self, agent: MineRLAgent, window_size: int=4):
        self.agent = agent
        self.window_size = window_size

    def __iter__(self):
        self._iter = 0

        # TODO: reset the agent's internal state and populate these with a FULL TRAJECTORY!
        self.expert_observations = []
        self.expert_actions = []
        self._expert_pairs = zip(self.expert_observations, self.expert_actions)

        self.window = []

    def __next__(self, dont_yield: bool=False):
        is_first = self._iter == 0
        self._iter += 1

        # should auto-raise StopIteration
        expert_observation, expert_action = self._expert_pairs.__next__()

        # precompute the expert embeddings
        expert_embedding = self.agent.get_embedding(expert_observation)
        self.window.append((expert_embedding, expert_action))
        if len(self.window) > self.window_size:
            self.window.pop(0)

        if is_first:
            # let the window fully populate
            for _ in range(self.window_size - 1):
                self.__next__(dont_yield=True)

        if len(self.window) != self.window_size:
            raise ValueError(f"Unexpected window size. Got {len(self.window)}, expected: {self.window_size}")

        if not dont_yield:
            yield self.window

    def decompose_window(self, window: List):
        embeddings = []
        actions = []
        for embedding, action in window:
            embeddings.append(embedding)
            actions.append(action)
        return embeddings, actions